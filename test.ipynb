{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'me', '']]\n",
      "he has \n",
      "[['ni', 'me', '']]\n",
      "me has \n",
      "[['ku', '', '']]\n",
      "to \n",
      "[['ku', '', '']]\n",
      "to \n",
      "[['ku', '', 'mu']]\n",
      "to him \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\" Stemming Algorithm\n",
    "This is the stemming algorithm, \n",
    "An algorithm for SWAHILI prefix and suffix stripping, providing you with the core componets of a word in Swahili,\n",
    "giving you the stem of the word, the English phrase of the word in a dictionary\n",
    "\n",
    "bavin2009@gmail.com\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# import en\n",
    "import nltk\n",
    "import sys\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class Stemmer:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"The main part of the stemming algorithm starts here.\n",
    "        b is a buffer holding a word to be stemmed. The letters are in b[k0],\n",
    "        b[k0+1] ... ending at b[k]. In fact k0 = 0 in this demo program. k is\n",
    "        readjusted downwards as the stemming progresses. Zero termination is\n",
    "        not in fact used in the algorithm.\n",
    "\n",
    "        Note that only lower case sequences are stemmed. Forcing to lower case\n",
    "        should be done before stem(...) is called.\n",
    "        \"\"\"\n",
    "\n",
    "        self.b = \"\"  # buffer for word to be stemmed\n",
    "        self.k = 0\n",
    "        self.k0 = 0\n",
    "        self.FTense = None\n",
    "        self.j = 0   # j is a general offset into the string\n",
    "        self.RESULT = defaultdict(lambda:[])\n",
    "        self.DICT = defaultdict(lambda:'')\n",
    "\n",
    "    def cons(self, i):\n",
    "        \"\"\"cons(i) is TRUE <=> b[i] is a consonant.\"\"\"\n",
    "        if self.b[i] == 'a' or self.b[i] == 'e' or self.b[i] == 'i' or self.b[i] == 'o' or self.b[i] == 'u':\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    def vowelinstem(self):\n",
    "        \"\"\"vowelinstem() is TRUE <=> k0,...j contains a vowel\"\"\"\n",
    "        for i in range(self.k0, self.j + 1):\n",
    "            if not self.cons(i):\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def starts(self,s):\n",
    "        \"\"\"starts(s) is TRUE <=> k0...k starts with string s\"\"\"\n",
    "        if(self.b.find(s, 0, len(s)) != -1):\n",
    "            return True;\n",
    "        else:\n",
    "            return False;\n",
    "\n",
    "    def ends(self, s):\n",
    "        \"\"\"ends(s) is TRUE <=> k0,...k ends with the string s.\"\"\"\n",
    "        length = len(s)\n",
    "        if s[length - 1] != self.b[self.k]: # tiny speed-up\n",
    "            return 0\n",
    "        if length > (self.k - self.k0 + 1):\n",
    "            return 0\n",
    "        if self.b[self.k-length+1:self.k+1] != s:\n",
    "            return 0\n",
    "        self.j = self.k - length\n",
    "        return 1\n",
    "\n",
    "    def setto(self, s):\n",
    "        \"\"\"setto(s) sets (j+1),...k to the characters in the string s, readjusting k.\"\"\"\n",
    "        length = len(s)\n",
    "        self.b = self.b[:self.j+1] + s + self.b[self.j+length+1:]\n",
    "        self.k = self.j + length\n",
    "\n",
    "    def r(self, s):\n",
    "        \"\"\"r(s) is used further down.\"\"\"\n",
    "        if self.m() > 0:\n",
    "            self.setto(s)\n",
    "\n",
    "    def step1ab(self):\n",
    "        \"\"\"step1ab() gets rid of plurals and -ed or -ing. e.g.\n",
    "           walipikia  -> alipik~\n",
    "           walipikiana ->  walipik\n",
    "           walichukuliwa -> walichuku\n",
    "           pikia      ->  pik\n",
    "           pangiwa    ->  pang \n",
    "\n",
    "           #CASES\n",
    "           pigiliwa\n",
    "        \"\"\"\n",
    "\n",
    "        self.KEY = self.b\n",
    "\n",
    "        if(len(self.b) > 4 and self.ends(\"kuwa\")):\n",
    "            J= len(self.b)\n",
    "            self.b = self.b[0:J]\n",
    "            self.k = J\n",
    "        else:\n",
    "            if self.b[self.k] == 'a':\n",
    "                if self.ends(\"eshwa\"):\n",
    "                    self.RESULT[self.KEY].append(\"made to be\")\n",
    "                    self.k = self.k - 5\n",
    "                if self.ends(\"lia\"):\n",
    "                    self.k = self.k - 3\n",
    "                elif self.ends(\"liana\"):\n",
    "                    self.RESULT[self.KEY].append(\"on behalf of each other\")\n",
    "                    self.k = self.k - 5\n",
    "                elif self.ends(\"eana\") or self.ends(\"iana\"):\n",
    "                    self.k = self.k - 4\n",
    "                    self.RESULT[self.KEY].append(\"at each other\")\n",
    "                elif self.ends(\"iliwa\"):\n",
    "                    self.k = self.k - 5\n",
    "                elif self.ends(\"liwa\"):\n",
    "                    self.k = self.k - 4\n",
    "                elif self.ends(\"iwa\"):\n",
    "                    self.k = self.k - 3\n",
    "                elif self.ends(\"jika\") or self.ends(\"lika\"):\n",
    "                    self.k = self.k - 3  #hitajika = hitaj, #kamilika = kamil\n",
    "                elif self.ends(\"ana\"):\n",
    "                    self.k = self.k - 3\n",
    "                    self.RESULT[self.KEY].append(\"each other\")\n",
    "                elif self.ends(\"ia\"):\n",
    "                    self.k = self.k - 2\n",
    "                    self.RESULT[self.KEY].append(\"for\")\n",
    "                elif self.ends(\"a\") and self.cons(self.k - 1):\n",
    "                    self.k = self.k - 1\n",
    "\n",
    "                self.b = self.b[0:self.k+1]\n",
    "            \n",
    "    def step1c(self):\n",
    "        \"\"\"step1c() Get rid of prefix complex Noun+verb, stripping off the propoun,tense,and object, leaving stem and suffix\"\"\"\n",
    "        p = re.compile('(ni|u|a|tu|m|mu|wa|i|li|ya|ki|vi|zi|ku|pa)(li|ta|na)?[a-z]{4}')\n",
    "        sol = p.match(self.b)\n",
    "        if(not sol):    #this ones checks to see if word is a verb so we can stem it if it's a verb\n",
    "            return False\n",
    "        else: return True;\n",
    "        \n",
    "\n",
    "    def STO(self,token, K):\n",
    "\n",
    "        if token == \"kuwa\": return \"were|will be|was\"\n",
    "\n",
    "        if K == 0:\n",
    "            #Subject Tokens\n",
    "            if token == \"ku\": return \"to\"\n",
    "            if token == \"wa\": return \"they\"\n",
    "            if token == \"ni\": return \"me\"\n",
    "            if token == \"tu\": return \"us\"\n",
    "            if token == \"mu\":  return \"you\"\n",
    "            if token == \"u\" : return \"you\"\n",
    "            if token == \"a\": return \"he\"\n",
    "            if token == \"i\": return \"it\"\n",
    "            if token == \"li\": return \"it\" \n",
    "            if token == \"ya\": \n",
    "                #self.FTense = 'PT'\n",
    "                return \"have\"\n",
    "\n",
    "\n",
    "        if K == 1:\n",
    "            #Time Tokens\n",
    "            if token == \"li\": return \"did,\"      #\"PT\" #PAST TENSE\n",
    "            if token == \"na\": return \"is,\"     #PRESENT TENSE\n",
    "            if token == \"ta\": return \"will,\"   #FUTURE TENSE\n",
    "            if token == \"ki\": return \"while,\"   #\"PT-CT|PR-CT\"\n",
    "            if token == \"mu\": return \"him,\"\n",
    "            if token == \"me\": return \"has,\"\n",
    "            if token == \"wa\": return \"them,\"\n",
    "\n",
    "\n",
    "        if K == 2:\n",
    "            #Object Tokens\n",
    "            if token == \"m\": return \"him\"\n",
    "            if token == \"wa\": return \"them\"\n",
    "            if token == \"tu\": return \"us\"\n",
    "            if token == \"ni\": return \"me\"\n",
    "            if token == \"ki\": return \"it\"\n",
    "\n",
    "    def step2(self):\n",
    "        \"\"\"step2() checks to see the various prefixes\n",
    "           #this checks to remove the first tokens that are for the Subject, Verb, Object. \n",
    "           #What remains is the root of the verb\n",
    "        \"\"\"\n",
    "        p = re.compile('(ni|u|a|tu|m|wa|i|li|ya|ki|vi|zi|ku|pa)(li|ta|na)(o)?[a-z]{3}')\n",
    "        p2 = re.compile('(ni|u|a|tu|m|wa|i|li|ya|ki|vi|zi|ku|pa)(me|li|ta|na)?(ni|tu|ku|mu|wa|cho)?[a-z]{2}')\n",
    "\n",
    "        #regex 3 = (ni|u|a|tu|m|wa|i|li|ya|ki|vi|zi|ku|pa)(li|ta|na)(ni|tu|ku|mu|wa|cho)?[a-z]{4}\n",
    "        \n",
    "        original = self.b\n",
    "\n",
    "        #storing tense of the action, to be converted in phrase\n",
    "        TENSE = None\n",
    "\n",
    "        #store the tokens here, which will be put together\n",
    "        RESULT = []\n",
    "        sol = p2.findall(self.b)\n",
    "        # T = map(list,sol)\n",
    "        T = list(map(list,sol))\n",
    "        print(T)\n",
    "\n",
    "        if len(list(T)) > 0:  \n",
    "            L = T[0]\n",
    "\n",
    "        newL = []\n",
    "\n",
    "        #Remove spaces in matching result\n",
    "        for j in range(len(L)):\n",
    "            t = L[j]\n",
    "            if len(t) > 0:\n",
    "                newL.append(t)\n",
    "        \n",
    "        L = newL\n",
    "        \n",
    "        #Now construct english phrase using dictionary and STO Lookup function above\n",
    "        for i in range(len(L)):\n",
    "            tok = L[i]\n",
    "            if i == 1:\n",
    "                w = self.STO(tok,i)\n",
    "                w = w.split(',')\n",
    "                TENSE = w[1]\n",
    "\n",
    "            K = len(tok)\n",
    "            if self.b == \"kuwa\": \n",
    "                RESULT.append(self.STO(self.b,i))\n",
    "                break;\n",
    "            if K > 0:\n",
    "                RESULT.append(self.STO(tok,i)) #process the subject, tense and object\n",
    "                self.b = self.b[K:]\n",
    "\n",
    "        lemma = ''\n",
    "\n",
    "        #remove any odd spaces around the stem\n",
    "        self.b = self.b.strip()\n",
    "\n",
    "        # print 'self.b',self.b\n",
    "        # print 'self.KEY',self.KEY\n",
    "    \n",
    "        #if stemmed word not in dict, just extend stem as I may have accidentally chopped it off\n",
    "        if(self.b not in self.DICT): \n",
    "            FOUND = self.KEY.index(self.b)\n",
    "            if(FOUND): \n",
    "                text = self.KEY[FOUND:]\n",
    "                lemma = self.DICT[text]\n",
    "        else:\n",
    "            lemma = self.DICT[self.b]\n",
    "            \n",
    "        # print 'lemma:',lemma\n",
    "        if len(lemma) > 0:\n",
    "            lemma = lemma[0].split(' ')[0]\n",
    "        # else:\n",
    "        #     print(lemma)\n",
    "              \n",
    "        #keep track if the lemma is transformed and added so we don't add twice\n",
    "        ADDED = 0\n",
    "\n",
    "        #convert tense of english version of lemma at this point    \n",
    "        if TENSE != None or self.FTense != None:\n",
    "            if TENSE == 'PT' or self.FTense == 'PT':\n",
    "                try:\n",
    "                    lemma = en.verb.past(lemma)\n",
    "                    ADDED = 1\n",
    "                    RESULT.append(lemma)\n",
    "                except:\n",
    "                    pass\n",
    "        elif TENSE == 'PR':\n",
    "                try:\n",
    "                    lemma = en.verb.present(lemma)\n",
    "                    ADDED = 1\n",
    "                    RESULT.append(lemma)\n",
    "                except:\n",
    "                    pass\n",
    "         \n",
    "        #Used with Nodebox English Engine to get Verb Tense\n",
    "        self.FTense = None\n",
    "\n",
    "        #Join to form phrase, ignoring the comma used for storing the Tense of Verb\n",
    "        phrase = ' '.join(RESULT)\n",
    "    \n",
    "        phrase = phrase.split(',')[0]\n",
    "        if(ADDED == 0):\n",
    "            phrase +=' '+ lemma\n",
    "    \n",
    "       # if lemma == \"throw\": \n",
    "            #print lemma, \" <=++++++++++++++ Lemma and Phrase +++++++++++=>\", phrase\n",
    "            #sys.exit()\n",
    "        #If I have a suffix, I have some knowledge on objects at which action is directed\n",
    "        \n",
    "        OBJECTS = ''\n",
    "        if len(self.RESULT[self.KEY]) == 1:\n",
    "            OBJECTS == self.RESULT[self.KEY][0]\n",
    "            self.RESULT[self.KEY] = []\n",
    "\n",
    "\n",
    "        #print \" self.RESULT[self.KEY]########\", self.RESULT[self.KEY]\n",
    "\n",
    "        #print lemma, \" <=++++++++++++++ Lemma and Result +++++++++++^^^2 =>\" ,RESULT, \"\\n <== PHRASE ==> \",phrase\n",
    "    \n",
    "        #Append this to a dictionary, with key as original word, value as the phrase   \n",
    "        self.RESULT[self.KEY].append(lemma) #store stem in first index\n",
    "        self.RESULT[self.KEY].append(phrase) #store result as a list whose key is the original word in sentence\n",
    "       \n",
    "    def stem(self, p, i=None, j=None):\n",
    "        \"\"\"In stem(p,i,j), p is a char pointer, and the string to be stemmed\n",
    "        is from p[i] to p[j] inclusive. Typically i is zero and j is the\n",
    "        offset to the last character of a string, (p[j+1] == '\\0'). The\n",
    "        stemmer adjusts the characters p[i] ... p[j] and returns the new\n",
    "        end-point of the string, k. Stemming never increases word length, so\n",
    "        i <= k <= j. To turn the stemmer into a module, declare 'stem' as\n",
    "        extern, and delete the remainder of this file.\n",
    "        \"\"\"\n",
    "        # print 'stemming...',p\n",
    "        if i is None:\n",
    "            i = 0\n",
    "        if j is None:\n",
    "            j = len(p) - 1\n",
    "        # copy the parameters into statics\n",
    "        self.b = p\n",
    "        self.k = j\n",
    "        self.k0 = i\n",
    "        if self.k <= self.k0 + 1:\n",
    "            return self.b \n",
    "\n",
    "        K = 0\n",
    "        \n",
    "        if(self.step1c()):\n",
    "            K = 1\n",
    "            self.step1ab() #only stem the verb form words rather than nouns\n",
    "       \n",
    "        #If complex V+N, stem the prefix in order to parse the complex verb+Noun\n",
    "        if(K): \n",
    "            self.step2()\n",
    "\n",
    "        return self.b[self.k0:self.k+1]\n",
    "    \n",
    "    def input(self, line):\n",
    "        p = self\n",
    "        word = line[0]\n",
    "        output = ''\n",
    "        output += p.stem(word, 0,len(word)-1)\n",
    "        if len(self.RESULT[word]) == 2 : \n",
    "            return self.RESULT[word][1]\n",
    "        else: return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Stemmer()\n",
    "    # p.input( ['amesema','amezungumzia'] )\n",
    "    # p.input( ['amesema'] )\n",
    "    print (p.input( ['amesema'] ))\n",
    "    print (p.input( ['nimepata'] ))\n",
    "    print (p.input( ['kuendesha'] ))\n",
    "    print (p.input( ['kuendeshawa'] ))\n",
    "    print (p.input( ['kumuua'] ))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f680a5a80362cd3edb1c14020f5e5370ae53c03100fbbb1b1fcac0ee8a30d29d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
